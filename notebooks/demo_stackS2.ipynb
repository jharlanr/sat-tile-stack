{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "979725a4-9ef2-472f-a842-becc513b38fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## ======= ##\n",
    "## IMPORTS ##\n",
    "## ======= ##\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import xarray as xr\n",
    "import zarr\n",
    "import rioxarray\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import dask\n",
    "import dask.array\n",
    "import math\n",
    "\n",
    "import datetime\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import pystac_client\n",
    "from pystac.extensions.projection import ProjectionExtension as proj\n",
    "\n",
    "import planetary_computer\n",
    "import rasterio\n",
    "import rasterio.features\n",
    "from rasterio.features import rasterize\n",
    "\n",
    "import stackstac\n",
    "import pyproj\n",
    "\n",
    "import dask.diagnostics\n",
    "\n",
    "from shapely.geometry import box\n",
    "from shapely.ops import transform\n",
    "\n",
    "from scipy.ndimage import binary_propagation\n",
    "from scipy.ndimage import label\n",
    "\n",
    "import sat_tile_stack\n",
    "from sat_tile_stack import sattile_stack, sat_mask_array, write_netcdf_from_da\n",
    "from sat_tile_stack import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8e4e8d35-e7f8-488d-8edf-0d3d6e487fe2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connected to Microsoft Planetary Computer\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e88dd62844644e869be6bbe52c00e146",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing lakes:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " working on lake CW2019_1524\n",
      "epsg for bounds_latlon: 3413\n",
      "pulling stack into memory, shape will be: (153, 8, 512, 512)\n",
      "[########################################] | 100% Completed | 76.78 s\n",
      "shape of stack in memory: (153, 8, 512, 512)\n",
      "wrote /home/jupyter/data/CW2019_tstacks/tstack_CW2019_1524.nc\n",
      "lake CW2019_1524 → 0:02:57.430145\n",
      "\n",
      " working on lake CW2019_1525\n",
      "epsg for bounds_latlon: 3413\n",
      "pulling stack into memory, shape will be: (153, 8, 512, 512)\n",
      "[########################################] | 100% Completed | 43.44 s\n",
      "shape of stack in memory: (153, 8, 512, 512)\n",
      "wrote /home/jupyter/data/CW2019_tstacks/tstack_CW2019_1525.nc\n",
      "lake CW2019_1525 → 0:01:40.074941\n",
      "\n",
      " working on lake CW2019_1526\n",
      "epsg for bounds_latlon: 3413\n",
      "pulling stack into memory, shape will be: (153, 8, 512, 512)\n",
      "[########################################] | 100% Completed | 46.63 s\n",
      "shape of stack in memory: (153, 8, 512, 512)\n",
      "wrote /home/jupyter/data/CW2019_tstacks/tstack_CW2019_1526.nc\n",
      "lake CW2019_1526 → 0:01:46.761808\n",
      "\n",
      " working on lake CW2019_1527\n",
      "epsg for bounds_latlon: 3413\n",
      "pulling stack into memory, shape will be: (153, 8, 512, 512)\n",
      "[########################################] | 100% Completed | 45.87 s\n",
      "shape of stack in memory: (153, 8, 512, 512)\n",
      "wrote /home/jupyter/data/CW2019_tstacks/tstack_CW2019_1527.nc\n",
      "lake CW2019_1527 → 0:01:48.835150\n",
      "\n",
      " working on lake CW2019_1528\n",
      "epsg for bounds_latlon: 3413\n",
      "pulling stack into memory, shape will be: (153, 8, 512, 512)\n",
      "[########################################] | 100% Completed | 40.86 s\n",
      "shape of stack in memory: (153, 8, 512, 512)\n",
      "wrote /home/jupyter/data/CW2019_tstacks/tstack_CW2019_1528.nc\n",
      "lake CW2019_1528 → 0:01:36.962311\n",
      "\n",
      " working on lake CW2019_1529\n",
      "epsg for bounds_latlon: 3413\n",
      "pulling stack into memory, shape will be: (153, 8, 512, 512)\n",
      "[########################################] | 100% Completed | 34.48 s\n",
      "shape of stack in memory: (153, 8, 512, 512)\n",
      "wrote /home/jupyter/data/CW2019_tstacks/tstack_CW2019_1529.nc\n",
      "lake CW2019_1529 → 0:01:19.152950\n",
      "\n",
      " working on lake CW2019_1530\n",
      "epsg for bounds_latlon: 3413\n",
      "pulling stack into memory, shape will be: (153, 8, 512, 512)\n",
      "[########################################] | 100% Completed | 44.38 s\n",
      "shape of stack in memory: (153, 8, 512, 512)\n",
      "wrote /home/jupyter/data/CW2019_tstacks/tstack_CW2019_1530.nc\n",
      "lake CW2019_1530 → 0:01:40.162766\n",
      "\n",
      " working on lake CW2019_1531\n",
      "epsg for bounds_latlon: 3413\n",
      "pulling stack into memory, shape will be: (153, 8, 512, 512)\n",
      "[########################################] | 100% Completed | 38.46 s\n",
      "shape of stack in memory: (153, 8, 512, 512)\n",
      "wrote /home/jupyter/data/CW2019_tstacks/tstack_CW2019_1531.nc\n",
      "lake CW2019_1531 → 0:01:27.356586\n",
      "\n",
      " working on lake CW2019_1532\n",
      "epsg for bounds_latlon: 3413\n",
      "pulling stack into memory, shape will be: (153, 8, 512, 512)\n",
      "[########################################] | 100% Completed | 37.32 s\n",
      "shape of stack in memory: (153, 8, 512, 512)\n",
      "wrote /home/jupyter/data/CW2019_tstacks/tstack_CW2019_1532.nc\n",
      "lake CW2019_1532 → 0:01:24.659274\n",
      "\n",
      " working on lake CW2019_1533\n",
      "epsg for bounds_latlon: 3413\n",
      "pulling stack into memory, shape will be: (153, 8, 512, 512)\n",
      "[########################################] | 100% Completed | 46.32 s\n",
      "shape of stack in memory: (153, 8, 512, 512)\n",
      "wrote /home/jupyter/data/CW2019_tstacks/tstack_CW2019_1533.nc\n",
      "lake CW2019_1533 → 0:01:40.995145\n",
      "\n",
      " working on lake CW2019_1534\n",
      "epsg for bounds_latlon: 3413\n",
      "pulling stack into memory, shape will be: (153, 8, 512, 512)\n",
      "[########################################] | 100% Completed | 37.33 s\n",
      "shape of stack in memory: (153, 8, 512, 512)\n",
      "wrote /home/jupyter/data/CW2019_tstacks/tstack_CW2019_1534.nc\n",
      "lake CW2019_1534 → 0:01:29.095968\n",
      "\n",
      " working on lake CW2019_1535\n",
      "epsg for bounds_latlon: 3413\n",
      "pulling stack into memory, shape will be: (153, 8, 512, 512)\n",
      "[########################################] | 100% Completed | 52.68 s\n",
      "shape of stack in memory: (153, 8, 512, 512)\n",
      "wrote /home/jupyter/data/CW2019_tstacks/tstack_CW2019_1535.nc\n",
      "lake CW2019_1535 → 0:02:01.061523\n",
      "\n",
      " working on lake CW2019_1536\n",
      "epsg for bounds_latlon: 3413\n",
      "pulling stack into memory, shape will be: (153, 8, 512, 512)\n",
      "[########################################] | 100% Completed | 41.34 s\n",
      "shape of stack in memory: (153, 8, 512, 512)\n",
      "wrote /home/jupyter/data/CW2019_tstacks/tstack_CW2019_1536.nc\n",
      "lake CW2019_1536 → 0:01:31.000412\n",
      "\n",
      " working on lake CW2019_1537\n",
      "epsg for bounds_latlon: 3413\n",
      "pulling stack into memory, shape will be: (153, 8, 512, 512)\n",
      "[########################################] | 100% Completed | 52.98 s\n",
      "shape of stack in memory: (153, 8, 512, 512)\n",
      "wrote /home/jupyter/data/CW2019_tstacks/tstack_CW2019_1537.nc\n",
      "lake CW2019_1537 → 0:01:55.902172\n",
      "\n",
      " working on lake CW2019_1538\n",
      "epsg for bounds_latlon: 3413\n",
      "pulling stack into memory, shape will be: (153, 8, 512, 512)\n",
      "[########################################] | 100% Completed | 38.47 s\n",
      "shape of stack in memory: (153, 8, 512, 512)\n",
      "wrote /home/jupyter/data/CW2019_tstacks/tstack_CW2019_1538.nc\n",
      "lake CW2019_1538 → 0:01:28.324929\n",
      "\n",
      " working on lake CW2019_1539\n",
      "epsg for bounds_latlon: 3413\n",
      "pulling stack into memory, shape will be: (153, 8, 512, 512)\n",
      "[########################################] | 100% Completed | 52.77 s\n",
      "shape of stack in memory: (153, 8, 512, 512)\n",
      "wrote /home/jupyter/data/CW2019_tstacks/tstack_CW2019_1539.nc\n",
      "lake CW2019_1539 → 0:01:55.158907\n",
      "\n",
      " working on lake CW2019_1540\n",
      "epsg for bounds_latlon: 3413\n",
      "pulling stack into memory, shape will be: (153, 8, 512, 512)\n",
      "[########################################] | 100% Completed | 36.98 s\n",
      "shape of stack in memory: (153, 8, 512, 512)\n",
      "wrote /home/jupyter/data/CW2019_tstacks/tstack_CW2019_1540.nc\n",
      "lake CW2019_1540 → 0:01:22.083441\n",
      "\n",
      " working on lake CW2019_1541\n",
      "epsg for bounds_latlon: 3413\n",
      "pulling stack into memory, shape will be: (153, 8, 512, 512)\n",
      "[########################################] | 100% Completed | 46.86 s\n",
      "shape of stack in memory: (153, 8, 512, 512)\n",
      "wrote /home/jupyter/data/CW2019_tstacks/tstack_CW2019_1541.nc\n",
      "lake CW2019_1541 → 0:01:45.089211\n",
      "\n",
      " working on lake CW2019_1542\n",
      "epsg for bounds_latlon: 3413\n",
      "pulling stack into memory, shape will be: (153, 8, 512, 512)\n",
      "[########################################] | 100% Completed | 65.04 s\n",
      "shape of stack in memory: (153, 8, 512, 512)\n",
      "wrote /home/jupyter/data/CW2019_tstacks/tstack_CW2019_1542.nc\n",
      "lake CW2019_1542 → 0:02:23.392402\n",
      "\n",
      " working on lake CW2019_1543\n",
      "epsg for bounds_latlon: 3413\n",
      "pulling stack into memory, shape will be: (153, 8, 512, 512)\n",
      "[########################################] | 100% Completed | 52.72 s\n",
      "shape of stack in memory: (153, 8, 512, 512)\n",
      "wrote /home/jupyter/data/CW2019_tstacks/tstack_CW2019_1543.nc\n",
      "lake CW2019_1543 → 0:01:55.268487\n",
      "\n",
      " working on lake CW2019_1544\n",
      "epsg for bounds_latlon: 3413\n",
      "pulling stack into memory, shape will be: (153, 8, 512, 512)\n",
      "[########################################] | 100% Completed | 48.11 s\n",
      "shape of stack in memory: (153, 8, 512, 512)\n",
      "wrote /home/jupyter/data/CW2019_tstacks/tstack_CW2019_1544.nc\n",
      "lake CW2019_1544 → 0:01:47.113006\n",
      "\n",
      " working on lake CW2019_1545\n",
      "epsg for bounds_latlon: 3413\n",
      "pulling stack into memory, shape will be: (153, 8, 512, 512)\n",
      "[########################################] | 100% Completed | 44.66 s\n",
      "shape of stack in memory: (153, 8, 512, 512)\n",
      "wrote /home/jupyter/data/CW2019_tstacks/tstack_CW2019_1545.nc\n",
      "lake CW2019_1545 → 0:01:39.477926\n",
      "\n",
      " working on lake CW2019_1546\n",
      "epsg for bounds_latlon: 3413\n",
      "pulling stack into memory, shape will be: (153, 8, 512, 512)\n",
      "[########################################] | 100% Completed | 36.47 s\n",
      "shape of stack in memory: (153, 8, 512, 512)\n",
      "wrote /home/jupyter/data/CW2019_tstacks/tstack_CW2019_1546.nc\n",
      "lake CW2019_1546 → 0:01:21.960443\n",
      "\n",
      " working on lake CW2019_1547\n",
      "epsg for bounds_latlon: 3413\n",
      "pulling stack into memory, shape will be: (153, 8, 512, 512)\n",
      "[########################################] | 100% Completed | 57.17 s\n",
      "shape of stack in memory: (153, 8, 512, 512)\n",
      "wrote /home/jupyter/data/CW2019_tstacks/tstack_CW2019_1547.nc\n",
      "lake CW2019_1547 → 0:02:06.047312\n",
      "\n",
      " working on lake CW2019_1548\n",
      "epsg for bounds_latlon: 3413\n",
      "pulling stack into memory, shape will be: (153, 8, 512, 512)\n",
      "[########################################] | 100% Completed | 40.37 s\n",
      "shape of stack in memory: (153, 8, 512, 512)\n",
      "wrote /home/jupyter/data/CW2019_tstacks/tstack_CW2019_1548.nc\n",
      "lake CW2019_1548 → 0:01:25.381400\n",
      "\n",
      " working on lake CW2019_1549\n",
      "epsg for bounds_latlon: 3413\n",
      "pulling stack into memory, shape will be: (153, 8, 512, 512)\n",
      "[########                                ] | 21% Completed | 36.11 ss\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error opening 'https://sentinel2l2a01.blob.core.windows.net/sentinel2-l2/22/W/EB/2019/05/15/S2B_MSIL2A_20190515T152819_N0212_R111_T22WEB_20201106T003737.SAFE/GRANULE/L2A_T22WEB_A011434_20190515T153250/IMG_DATA/R20m/T22WEB_20190515T152819_B12_20m.tif?st=2025-12-28T17%3A07%3A04Z&se=2025-12-29T17%3A52%3A04Z&sp=rl&sv=2025-07-05&sr=c&skoid=9c8ff44a-6a2c-4dfb-b298-1c9212f64d9a&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2025-12-29T05%3A45%3A07Z&ske=2026-01-05T05%3A45%3A07Z&sks=b&skv=2025-07-05&sig=G0oi1CXXzm1JA/d//8q%2BJhv%2BYqgoVLLyQPlGGmp%2B4O0%3D': RasterioIOError(\"'/vsicurl/https://sentinel2l2a01.blob.core.windows.net/sentinel2-l2/22/W/EB/2019/05/15/S2B_MSIL2A_20190515T152819_N0212_R111_T22WEB_20201106T003737.SAFE/GRANULE/L2A_T22WEB_A011434_20190515T153250/IMG_DATA/R20m/T22WEB_20190515T152819_B12_20m.tif?st=2025-12-28T17%3A07%3A04Z&se=2025-12-29T17%3A52%3A04Z&sp=rl&sv=2025-07-05&sr=c&skoid=9c8ff44a-6a2c-4dfb-b298-1c9212f64d9a&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2025-12-29T05%3A45%3A07Z&ske=2026-01-05T05%3A45%3A07Z&sks=b&skv=2025-07-05&sig=G0oi1CXXzm1JA/d//8q%2BJhv%2BYqgoVLLyQPlGGmp%2B4O0%3D' not recognized as being in a supported file format.\")",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCPLE_OpenFailedError\u001b[0m                      Traceback (most recent call last)",
      "File \u001b[0;32mrasterio/_base.pyx:310\u001b[0m, in \u001b[0;36mrasterio._base.DatasetBase.__init__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mrasterio/_base.pyx:221\u001b[0m, in \u001b[0;36mrasterio._base.open_dataset\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mrasterio/_err.pyx:359\u001b[0m, in \u001b[0;36mrasterio._err.exc_wrap_pointer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mCPLE_OpenFailedError\u001b[0m: '/vsicurl/https://sentinel2l2a01.blob.core.windows.net/sentinel2-l2/22/W/EB/2019/05/15/S2B_MSIL2A_20190515T152819_N0212_R111_T22WEB_20201106T003737.SAFE/GRANULE/L2A_T22WEB_A011434_20190515T153250/IMG_DATA/R20m/T22WEB_20190515T152819_B12_20m.tif?st=2025-12-28T17%3A07%3A04Z&se=2025-12-29T17%3A52%3A04Z&sp=rl&sv=2025-07-05&sr=c&skoid=9c8ff44a-6a2c-4dfb-b298-1c9212f64d9a&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2025-12-29T05%3A45%3A07Z&ske=2026-01-05T05%3A45%3A07Z&sks=b&skv=2025-07-05&sig=G0oi1CXXzm1JA/d//8q%2BJhv%2BYqgoVLLyQPlGGmp%2B4O0%3D' not recognized as being in a supported file format.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRasterioIOError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/stackstac/rio_reader.py:325\u001b[0m, in \u001b[0;36mAutoParallelRioReader._open\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 325\u001b[0m     ds \u001b[38;5;241m=\u001b[39m \u001b[43mSelfCleaningDatasetReader\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msharing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32mrasterio/_base.pyx:312\u001b[0m, in \u001b[0;36mrasterio._base.DatasetBase.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mRasterioIOError\u001b[0m: '/vsicurl/https://sentinel2l2a01.blob.core.windows.net/sentinel2-l2/22/W/EB/2019/05/15/S2B_MSIL2A_20190515T152819_N0212_R111_T22WEB_20201106T003737.SAFE/GRANULE/L2A_T22WEB_A011434_20190515T153250/IMG_DATA/R20m/T22WEB_20190515T152819_B12_20m.tif?st=2025-12-28T17%3A07%3A04Z&se=2025-12-29T17%3A52%3A04Z&sp=rl&sv=2025-07-05&sr=c&skoid=9c8ff44a-6a2c-4dfb-b298-1c9212f64d9a&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2025-12-29T05%3A45%3A07Z&ske=2026-01-05T05%3A45%3A07Z&sks=b&skv=2025-07-05&sig=G0oi1CXXzm1JA/d//8q%2BJhv%2BYqgoVLLyQPlGGmp%2B4O0%3D' not recognized as being in a supported file format.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 56\u001b[0m\n\u001b[1;32m     53\u001b[0m centroid \u001b[38;5;241m=\u001b[39m (gdf\u001b[38;5;241m.\u001b[39miloc[idx_lake]\u001b[38;5;241m.\u001b[39mcentroid_x, gdf\u001b[38;5;241m.\u001b[39miloc[idx_lake]\u001b[38;5;241m.\u001b[39mcentroid_y)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# CALL FUNCTION TO GENERATE TIMESTACK\u001b[39;00m\n\u001b[0;32m---> 56\u001b[0m timestack \u001b[38;5;241m=\u001b[39m \u001b[43msattile_stack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatalog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcentroid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mband_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpix_res\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtile_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_range\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtime_range\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcloudmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgdf_mask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx_lake\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpull_to_mem\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# WRITE TIMESTACK AS .nc FILE TO DISK\u001b[39;00m\n\u001b[1;32m     59\u001b[0m outfile \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/jupyter/data/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mregion\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00myear\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_tstacks/tstack_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgdf\u001b[38;5;241m.\u001b[39miloc[idx_lake]\u001b[38;5;241m.\u001b[39mnew_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.nc\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/repos/sat-tile-stack/src/sat_tile_stack/stack.py:214\u001b[0m, in \u001b[0;36msattile_stack\u001b[0;34m(catalog, centroid, band_names, pix_res, tile_size, time_range, normalize, cloudmask, mask, pull_to_mem)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpulling stack into memory, shape will be: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtimestack\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m dask\u001b[38;5;241m.\u001b[39mdiagnostics\u001b[38;5;241m.\u001b[39mProgressBar():\n\u001b[0;32m--> 214\u001b[0m     timestack_mem \u001b[38;5;241m=\u001b[39m \u001b[43mstack_to_pull\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape of stack in memory: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtimestack_mem\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m timestack_mem\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/xarray/core/dataarray.py:1207\u001b[0m, in \u001b[0;36mDataArray.compute\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   1182\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Manually trigger loading of this array's data from disk or a\u001b[39;00m\n\u001b[1;32m   1183\u001b[0m \u001b[38;5;124;03mremote source into memory and return a new array.\u001b[39;00m\n\u001b[1;32m   1184\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1204\u001b[0m \u001b[38;5;124;03mdask.compute\u001b[39;00m\n\u001b[1;32m   1205\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1206\u001b[0m new \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m-> 1207\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnew\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/xarray/core/dataarray.py:1175\u001b[0m, in \u001b[0;36mDataArray.load\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   1155\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mload\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:\n\u001b[1;32m   1156\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Manually trigger loading of this array's data from disk or a\u001b[39;00m\n\u001b[1;32m   1157\u001b[0m \u001b[38;5;124;03m    remote source into memory and return this array.\u001b[39;00m\n\u001b[1;32m   1158\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1173\u001b[0m \u001b[38;5;124;03m    dask.compute\u001b[39;00m\n\u001b[1;32m   1174\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1175\u001b[0m     ds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_to_temp_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1176\u001b[0m     new \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_from_temp_dataset(ds)\n\u001b[1;32m   1177\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable \u001b[38;5;241m=\u001b[39m new\u001b[38;5;241m.\u001b[39m_variable\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/xarray/core/dataset.py:541\u001b[0m, in \u001b[0;36mDataset.load\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    538\u001b[0m chunkmanager \u001b[38;5;241m=\u001b[39m get_chunked_array_type(\u001b[38;5;241m*\u001b[39mlazy_data\u001b[38;5;241m.\u001b[39mvalues())\n\u001b[1;32m    540\u001b[0m \u001b[38;5;66;03m# evaluate all the chunked arrays simultaneously\u001b[39;00m\n\u001b[0;32m--> 541\u001b[0m evaluated_data: \u001b[38;5;28mtuple\u001b[39m[np\u001b[38;5;241m.\u001b[39mndarray[Any, Any], \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mchunkmanager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    542\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mlazy_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    543\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    545\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(lazy_data, evaluated_data, strict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    546\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvariables[k]\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m data\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/xarray/namedarray/daskmanager.py:85\u001b[0m, in \u001b[0;36mDaskManager.compute\u001b[0;34m(self, *data, **kwargs)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute\u001b[39m(\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mdata: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any\n\u001b[1;32m     82\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[np\u001b[38;5;241m.\u001b[39mndarray[Any, _DType_co], \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]:\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marray\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m compute\n\u001b[0;32m---> 85\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/dask/base.py:681\u001b[0m, in \u001b[0;36mcompute\u001b[0;34m(traverse, optimize_graph, scheduler, get, *args, **kwargs)\u001b[0m\n\u001b[1;32m    678\u001b[0m     expr \u001b[38;5;241m=\u001b[39m expr\u001b[38;5;241m.\u001b[39moptimize()\n\u001b[1;32m    679\u001b[0m     keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(flatten(expr\u001b[38;5;241m.\u001b[39m__dask_keys__()))\n\u001b[0;32m--> 681\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mschedule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexpr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    683\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m repack(results)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/stackstac/to_dask.py:189\u001b[0m, in \u001b[0;36mfetch_raster_window\u001b[0;34m(reader_table, slices, dtype, fill_value)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;66;03m# Only read if the window we're fetching actually overlaps with the asset\u001b[39;00m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m windows\u001b[38;5;241m.\u001b[39mintersect(current_window, asset_window):\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;66;03m# NOTE: when there are multiple assets, we _could_ parallelize these reads with our own threadpool.\u001b[39;00m\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;66;03m# However, that would probably increase memory usage, since the internal, thread-local GDAL datasets\u001b[39;00m\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;66;03m# would end up copied to even more threads.\u001b[39;00m\n\u001b[1;32m    187\u001b[0m \n\u001b[1;32m    188\u001b[0m     \u001b[38;5;66;03m# TODO when the Reader won't be rescaling, support passing `output` to avoid the copy?\u001b[39;00m\n\u001b[0;32m--> 189\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mreader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_window\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    191\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m all_empty:\n\u001b[1;32m    192\u001b[0m         \u001b[38;5;66;03m# Turn `output` from a broadcast-trick array to a real array, so it's writeable\u001b[39;00m\n\u001b[1;32m    193\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    194\u001b[0m             np\u001b[38;5;241m.\u001b[39misnan(data)\n\u001b[1;32m    195\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39misnan(fill_value)\n\u001b[1;32m    196\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m np\u001b[38;5;241m.\u001b[39mequal(data, fill_value)\n\u001b[1;32m    197\u001b[0m         )\u001b[38;5;241m.\u001b[39mall():\n\u001b[1;32m    198\u001b[0m             \u001b[38;5;66;03m# Unless the data we just read is all empty anyway\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/stackstac/rio_reader.py:383\u001b[0m, in \u001b[0;36mAutoParallelRioReader.read\u001b[0;34m(self, window, **kwargs)\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mread\u001b[39m(\u001b[38;5;28mself\u001b[39m, window: Window, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[0;32m--> 383\u001b[0m     reader \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    385\u001b[0m         result \u001b[38;5;241m=\u001b[39m reader\u001b[38;5;241m.\u001b[39mread(\n\u001b[1;32m    386\u001b[0m             window\u001b[38;5;241m=\u001b[39mwindow,\n\u001b[1;32m    387\u001b[0m             out_dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    391\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    392\u001b[0m         )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/stackstac/rio_reader.py:379\u001b[0m, in \u001b[0;36mAutoParallelRioReader.dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_lock:\n\u001b[1;32m    378\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 379\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    380\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/stackstac/rio_reader.py:334\u001b[0m, in \u001b[0;36mAutoParallelRioReader._open\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    329\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(msg)\n\u001b[1;32m    330\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m NodataReader(\n\u001b[1;32m    331\u001b[0m                 dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype, fill_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfill_value\n\u001b[1;32m    332\u001b[0m             )\n\u001b[0;32m--> 334\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ds\u001b[38;5;241m.\u001b[39mcount \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    336\u001b[0m     nr_of_bands \u001b[38;5;241m=\u001b[39m ds\u001b[38;5;241m.\u001b[39mcount\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error opening 'https://sentinel2l2a01.blob.core.windows.net/sentinel2-l2/22/W/EB/2019/05/15/S2B_MSIL2A_20190515T152819_N0212_R111_T22WEB_20201106T003737.SAFE/GRANULE/L2A_T22WEB_A011434_20190515T153250/IMG_DATA/R20m/T22WEB_20190515T152819_B12_20m.tif?st=2025-12-28T17%3A07%3A04Z&se=2025-12-29T17%3A52%3A04Z&sp=rl&sv=2025-07-05&sr=c&skoid=9c8ff44a-6a2c-4dfb-b298-1c9212f64d9a&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2025-12-29T05%3A45%3A07Z&ske=2026-01-05T05%3A45%3A07Z&sks=b&skv=2025-07-05&sig=G0oi1CXXzm1JA/d//8q%2BJhv%2BYqgoVLLyQPlGGmp%2B4O0%3D': RasterioIOError(\"'/vsicurl/https://sentinel2l2a01.blob.core.windows.net/sentinel2-l2/22/W/EB/2019/05/15/S2B_MSIL2A_20190515T152819_N0212_R111_T22WEB_20201106T003737.SAFE/GRANULE/L2A_T22WEB_A011434_20190515T153250/IMG_DATA/R20m/T22WEB_20190515T152819_B12_20m.tif?st=2025-12-28T17%3A07%3A04Z&se=2025-12-29T17%3A52%3A04Z&sp=rl&sv=2025-07-05&sr=c&skoid=9c8ff44a-6a2c-4dfb-b298-1c9212f64d9a&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2025-12-29T05%3A45%3A07Z&ske=2026-01-05T05%3A45%3A07Z&sks=b&skv=2025-07-05&sig=G0oi1CXXzm1JA/d//8q%2BJhv%2BYqgoVLLyQPlGGmp%2B4O0%3D' not recognized as being in a supported file format.\")"
     ]
    }
   ],
   "source": [
    "## =============================================================================== ##\n",
    "## LOOP OVER LAKES IN THE .csv FILE AND SAVE EACH TIMESTACK AS A SEPARATE .nc FILE ##\n",
    "## =============================================================================== ##\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import time, datetime as dt\n",
    "\n",
    "# READ IN THE LAKE INFORMATION .geojson FILE\n",
    "gdf = gpd.read_file(\"/home/jupyter/repos/sat-tile-stack/gdfs/labels_2019_volumes.geojson\")\n",
    "gdf['centroid'] = gdf.geometry.centroid\n",
    "gdf['centroid_x'] = gdf.centroid.x\n",
    "gdf['centroid_y'] = gdf.centroid.y\n",
    "gdf_mask = gdf\n",
    "\n",
    "# DECIDE WHETHER TO NORMALIZE THE IMAGERY UPON COMPLIING OR NOT\n",
    "normalize = False\n",
    "\n",
    "# SPECIFY TIME RANGE\n",
    "time_range = '2019-05-01/2019-09-30'\n",
    "\n",
    "# SPECIFY REGION (PICK FROM: NW, CW, SW, SE, NE, NO)\n",
    "region = 'CW'\n",
    "gdf = gdf[gdf['region'] == region]\n",
    "\n",
    "# SPECIFY YEAR (PICK FROM: 2018, 2019)\n",
    "year = '2019'\n",
    "\n",
    "## CONNECT TO MICROSOFT PLANETARY COMPUTER\n",
    "catalog = pystac_client.Client.open(\n",
    "    \"https://planetarycomputer.microsoft.com/api/stac/v1\",\n",
    "    modifier=planetary_computer.sign_inplace,)\n",
    "print(f\"connected to Microsoft Planetary Computer\")\n",
    "\n",
    "# SPECIFY IMAGERY BANDS\n",
    "band_names = [\"B04\",  # red (665 nm)\n",
    "              \"B03\",  # green (560 nm)\n",
    "              \"B02\",  # blue (490 nm)\n",
    "              \"B08\",  # NIR (842 nm)\n",
    "              \"B11\",  # SWIR1 (1610 nm)\n",
    "              \"B12\",  # SWIR2 (1.8 - 2.5 um)\n",
    "             ]\n",
    "\n",
    "total_start = time.perf_counter()\n",
    "\n",
    "# LOOP OVER LAKE LOCATIONS\n",
    "for idx_lake in tqdm(range(0,len(gdf)), desc=\"Processing lakes\"):\n",
    "    \n",
    "    iter_start = time.perf_counter()\n",
    "\n",
    "    print(f\"\\n working on lake {gdf.iloc[idx_lake].new_id}\")\n",
    "\n",
    "    # LAKE CENTROID\n",
    "    centroid = (gdf.iloc[idx_lake].centroid_x, gdf.iloc[idx_lake].centroid_y)\n",
    "\n",
    "    # CALL FUNCTION TO GENERATE TIMESTACK\n",
    "    timestack = sattile_stack(catalog, centroid, band_names, pix_res=10, tile_size=512, time_range=time_range, normalize=False, cloudmask=True, mask=gdf_mask.iloc[[idx_lake]], pull_to_mem=True)\n",
    "\n",
    "    # WRITE TIMESTACK AS .nc FILE TO DISK\n",
    "    outfile = f\"/home/jupyter/data/{region}{year}_tstacks/tstack_{gdf.iloc[idx_lake].new_id}.nc\"\n",
    "    os.makedirs(os.path.dirname(outfile), exist_ok=True) \n",
    "    write_netcdf_from_da(timestack, outfile)\n",
    "    os.chmod(outfile, 0o777) # permissions\n",
    "    \n",
    "    tqdm.write(f\"lake {gdf.iloc[idx_lake].new_id} → {dt.timedelta(seconds=time.perf_counter()-iter_start)}\")\n",
    "    \n",
    "tqdm.write(f\"all lakes → {dt.timedelta(seconds=time.perf_counter()-total_start)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b92dfa9-4471-46d7-bf44-ac98dec8f8df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d9c1be-0b1d-4863-ad40-f87d9d000b1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m129",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m129"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
